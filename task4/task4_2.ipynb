{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from biosppy.signals import *\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(x):\n",
    "    x -= np.mean(x)  \n",
    "    x /= np.std(x)\n",
    "    return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traindata = pd.read_csv(\"train_labels.csv\", header=0)   \n",
    "y_train = y_traindata.iloc[:,1].values\n",
    "\n",
    "testdata = pd.read_csv(\"test_eeg1.csv\", header=0)   \n",
    "y_testid = testdata.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(subject, file):\n",
    "    x_eeg1 = []\n",
    "    with open(\"{}_eeg1.csv\".format(file)) as f:\n",
    "        for line in f.readlines()[21600*(subject-1)+1:21600*subject+1]:\n",
    "            s = list(map(float, line.split(',')[1:]))\n",
    "            x_eeg1.append(s)\n",
    "    x_eeg1= np.array(x_eeg1)\n",
    "\n",
    "    x_eeg2 = []\n",
    "    with open(\"{}_eeg2.csv\".format(file)) as f:\n",
    "        for line in f.readlines()[21600*(subject-1)+1:21600*subject+1]:\n",
    "            s = list(map(float, line.split(',')[1:]))\n",
    "            x_eeg2.append(s)\n",
    "    x_eeg2  = np.array(x_eeg2)\n",
    "\n",
    "    x_emg = []\n",
    "    with open(\"{}_emg.csv\".format(file)) as f:\n",
    "        for line in f.readlines()[21600*(subject-1)+1:21600*subject+1]:\n",
    "            s = list(map(float, line.split(',')[1:]))\n",
    "            x_emg.append(s)\n",
    "    x_emg= np.array(x_emg)\n",
    "    return  x_eeg1,x_eeg2,x_emg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1_eeg1,  x_train_1_eeg2, x_train_1_emg  = read_data(1,'train')\n",
    "x_train_2_eeg1,  x_train_2_eeg2, x_train_2_emg  = read_data(2,'train')\n",
    "x_train_3_eeg1,  x_train_3_eeg2, x_train_3_emg  = read_data(3, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1_eeg1,  x_test_1_eeg2, x_test_1_emg  = read_data(1, 'test')\n",
    "x_test_2_eeg1,  x_test_2_eeg2, x_test_2_emg  = read_data(2, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = y_train[0:21600]-1\n",
    "label_2 = y_train[21600:43200]-1\n",
    "label_3 = y_train[43200:64800]-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eeg_feature_extraction(x):\n",
    "    X = np.zeros((512))\n",
    "    [ts, filtered_sig, features_ts,theta,alpha_low, alpha_high,beta, gamma, plf_pairs, plf]  = eeg.eeg(signal=x, sampling_rate=128.0, show=False)    \n",
    "    X = filtered_sig.reshape(512)\n",
    "\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def apply_fun(x):\n",
    "    result = []\n",
    "    for i in range(x.shape[0]):\n",
    "        result.append(eeg_feature_extraction(x[i]))\n",
    "    result = np.array(result)\n",
    "    return result\n",
    "\n",
    "def concatenate_eeg(x1, x2):\n",
    "    eeg = np.zeros((x1.shape[0], x1.shape[1], 2))\n",
    "    for i in range(x1.shape[0]):\n",
    "        eeg[i,:,0] = x1[i]\n",
    "        eeg[i,:,1] = x2[i]\n",
    "    return eeg\n",
    "\n",
    "def concatenate_total(eeg, emg):\n",
    "    data = np.zeros((eeg.shape[0], eeg.shape[1], 3))\n",
    "    for i in range(eeg.shape[0]):\n",
    "        data[i,:,:2] = eeg[i]\n",
    "        data[i,:,2] = emg[i]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_train_1_eeg1_extracted = apply_fun(x_train_1_eeg1.reshape(21600, 512, 1))\n",
    "x_train_1_eeg2_extracted = apply_fun(x_train_1_eeg2.reshape(21600, 512, 1))\n",
    "x_train_1_eeg = concatenate_eeg(x_train_1_eeg1_extracted , x_train_1_eeg2_extracted)\n",
    "x_train_1_eeg_stand = standardization(x_train_1_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "x_train_2_eeg1_extracted = apply_fun(x_train_2_eeg1.reshape(21600, 512, 1))\n",
    "x_train_2_eeg2_extracted = apply_fun(x_train_2_eeg2.reshape(21600, 512, 1))\n",
    "x_train_2_eeg = concatenate_eeg(x_train_2_eeg1_extracted , x_train_2_eeg2_extracted)\n",
    "x_train_2_eeg_stand = standardization(x_train_2_eeg)\n",
    "\n",
    "x_train_3_eeg1_extracted = apply_fun(x_train_3_eeg1.reshape(21600, 512, 1))\n",
    "x_train_3_eeg2_extracted = apply_fun(x_train_3_eeg2.reshape(21600, 512, 1))\n",
    "x_train_3_eeg = concatenate_eeg(x_train_3_eeg1_extracted , x_train_3_eeg2_extracted)\n",
    "x_train_3_eeg_stand = standardization(x_train_3_eeg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1_emg_stand = standardization(x_train_1_emg)\n",
    "x_train_1 = concatenate_total(x_train_1_eeg_stand, x_train_1_emg_stand)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_2_emg_stand = standardization(x_train_2_emg)\n",
    "x_train_2 = concatenate_total(x_train_2_eeg_stand, x_train_2_emg_stand)\n",
    "x_train_3_emg_stand = standardization(x_train_3_emg)\n",
    "x_train_3 = concatenate_total(x_train_3_eeg_stand, x_train_3_emg_stand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "nn_train_emg = np.concatenate((x_train_1,x_train_3),axis = 0)\n",
    "label_total = np.concatenate((label_1, label_3), axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22265\n",
      "18486\n",
      "2449\n"
     ]
    }
   ],
   "source": [
    "print(sum(label_total == 0))\n",
    "print(sum(label_total == 1))\n",
    "print(sum(label_total == 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "del_0_idx: [8667  279 7146]\n",
      "del_1_idx: [ 7856   561 18067]\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "class0_idx = np.where(label_total == 0)[0]\n",
    "class1_idx = np.where(label_total == 1)[0]\n",
    "del_class0_idx = np.random.choice(class0_idx, size = len(class0_idx)-sum(label_total  == 2), replace=False) \n",
    "del_class1_idx = np.random.choice(class1_idx, size = len(class1_idx)-sum(label_total  == 2), replace=False) \n",
    "print('del_0_idx:', del_class0_idx[:3])\n",
    "print('del_1_idx:', del_class1_idx[:3])\n",
    "nn_train_deleted = np.delete(nn_train_emg, (np.hstack((del_class0_idx, del_class1_idx))), axis = 0) \n",
    "label_total_deleted = np.delete(label_total, (np.hstack((del_class0_idx, del_class1_idx))), axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_total_trans = keras.utils.to_categorical(label_total_deleted, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7347, 3)\n",
      "(7347, 512, 3)\n"
     ]
    }
   ],
   "source": [
    "print(label_total_trans.shape)\n",
    "print(nn_train_deleted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_50 (Conv1D)           (None, 508, 10)           160       \n",
      "_________________________________________________________________\n",
      "dropout_116 (Dropout)        (None, 508, 10)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_51 (Conv1D)           (None, 499, 50)           5050      \n",
      "_________________________________________________________________\n",
      "dropout_117 (Dropout)        (None, 499, 50)           0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 249, 50)           0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 249, 20)           5680      \n",
      "_________________________________________________________________\n",
      "dropout_118 (Dropout)        (None, 249, 20)           0         \n",
      "_________________________________________________________________\n",
      "flatten_20 (Flatten)         (None, 4980)              0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 1000)              4981000   \n",
      "_________________________________________________________________\n",
      "dropout_119 (Dropout)        (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dropout_120 (Dropout)        (None, 500)               0         \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 100)               50100     \n",
      "_________________________________________________________________\n",
      "dropout_121 (Dropout)        (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_70 (Dense)             (None, 3)                 303       \n",
      "=================================================================\n",
      "Total params: 5,542,793\n",
      "Trainable params: 5,542,793\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nn = Sequential()\n",
    "nn.add(InputLayer((512,3)))\n",
    "# nn.add(Conv1D(100, 30, strides=1, activation='relu'))\n",
    "# nn.add(Dropout(0.3))\n",
    "nn.add(Conv1D(10, 5, strides=1, activation='relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Conv1D(50, 10, strides=1, activation='relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "# nn.add(Conv1D(100, 20, strides=1, activation='relu'))\n",
    "# nn.add(Dropout(0.3))\n",
    "nn.add(MaxPooling1D(2))\n",
    "# nn.add(Conv1D(50, 30, strides=1, activation='relu'))\n",
    "# nn.add(Dropout(0.3))\n",
    "# nn.add(Conv1D(10, 30, strides=1, activation='relu'))\n",
    "# nn.add(Dropout(0.3))\n",
    "nn.add(LSTM(20, activation ='relu', return_sequences= True, return_state= False))\n",
    "nn.add(Dropout(0.1))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(1000,activation = 'relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "# nn.add(Dense(200,activation = 'relu'))\n",
    "# nn.add(Dropout(0.3))\n",
    "nn.add(Dense(500,activation = 'relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Dense(100,activation = 'relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Dense(3,activation = 'softmax'))\n",
    "optim = keras.optimizers.Adadelta()\n",
    "nn.compile(optimizer=optim,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['categorical_accuracy'])\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 73s - loss: 0.9681 - categorical_accuracy: 0.4846\n",
      "Epoch 2/200\n",
      " - 64s - loss: 0.6839 - categorical_accuracy: 0.6746\n",
      "Epoch 3/200\n",
      " - 64s - loss: 0.6361 - categorical_accuracy: 0.7264\n",
      "Epoch 4/200\n",
      " - 66s - loss: 0.5396 - categorical_accuracy: 0.7735\n",
      "Epoch 5/200\n",
      " - 66s - loss: 0.4716 - categorical_accuracy: 0.8138\n",
      "Epoch 6/200\n",
      " - 65s - loss: 0.4183 - categorical_accuracy: 0.8312\n",
      "Epoch 7/200\n",
      " - 64s - loss: 0.3768 - categorical_accuracy: 0.8578\n",
      "Epoch 8/200\n",
      " - 64s - loss: 0.3160 - categorical_accuracy: 0.8857\n",
      "Epoch 9/200\n",
      " - 65s - loss: 0.2865 - categorical_accuracy: 0.8986\n",
      "Epoch 10/200\n",
      " - 66s - loss: 0.2845 - categorical_accuracy: 0.8976\n",
      "Epoch 11/200\n",
      " - 67s - loss: 0.2726 - categorical_accuracy: 0.8998\n",
      "Epoch 12/200\n",
      " - 64s - loss: 0.2524 - categorical_accuracy: 0.9077\n",
      "Epoch 13/200\n",
      " - 64s - loss: 0.2638 - categorical_accuracy: 0.9039\n",
      "Epoch 14/200\n",
      " - 65s - loss: 0.2558 - categorical_accuracy: 0.9058\n",
      "Epoch 15/200\n",
      " - 66s - loss: 0.2459 - categorical_accuracy: 0.9098\n",
      "Epoch 16/200\n",
      " - 64s - loss: 0.2349 - categorical_accuracy: 0.9151\n",
      "Epoch 17/200\n",
      " - 64s - loss: 0.2405 - categorical_accuracy: 0.9115\n",
      "Epoch 18/200\n",
      " - 64s - loss: 0.2110 - categorical_accuracy: 0.9250\n",
      "Epoch 19/200\n",
      " - 64s - loss: 0.2291 - categorical_accuracy: 0.9174\n",
      "Epoch 20/200\n",
      " - 64s - loss: 0.2355 - categorical_accuracy: 0.9137\n",
      "Epoch 21/200\n",
      " - 64s - loss: 0.2047 - categorical_accuracy: 0.9254\n",
      "Epoch 22/200\n",
      " - 64s - loss: 0.2158 - categorical_accuracy: 0.9234\n",
      "Epoch 23/200\n",
      " - 64s - loss: 0.1830 - categorical_accuracy: 0.9349\n",
      "Epoch 24/200\n",
      " - 64s - loss: 0.2057 - categorical_accuracy: 0.9251\n",
      "Epoch 25/200\n",
      " - 67s - loss: 0.1865 - categorical_accuracy: 0.9273\n",
      "Epoch 26/200\n",
      " - 66s - loss: 0.1794 - categorical_accuracy: 0.9353\n",
      "Epoch 27/200\n",
      " - 66s - loss: 0.1808 - categorical_accuracy: 0.9330\n",
      "Epoch 28/200\n",
      " - 65s - loss: 0.1780 - categorical_accuracy: 0.9353\n",
      "Epoch 29/200\n",
      " - 65s - loss: 0.1742 - categorical_accuracy: 0.9347\n",
      "Epoch 30/200\n",
      " - 65s - loss: 0.1658 - categorical_accuracy: 0.9374\n",
      "Epoch 31/200\n",
      " - 65s - loss: 0.1512 - categorical_accuracy: 0.9445\n",
      "Epoch 32/200\n",
      " - 65s - loss: 0.1543 - categorical_accuracy: 0.9394\n",
      "Epoch 33/200\n",
      " - 65s - loss: 0.1420 - categorical_accuracy: 0.9471\n",
      "Epoch 34/200\n",
      " - 66s - loss: 0.1690 - categorical_accuracy: 0.9378\n",
      "Epoch 35/200\n",
      " - 65s - loss: 0.1140 - categorical_accuracy: 0.9588\n",
      "Epoch 36/200\n",
      " - 66s - loss: 0.1285 - categorical_accuracy: 0.9530\n",
      "Epoch 37/200\n",
      " - 65s - loss: 0.0989 - categorical_accuracy: 0.9626\n",
      "Epoch 38/200\n",
      " - 66s - loss: 0.1248 - categorical_accuracy: 0.9548\n",
      "Epoch 39/200\n",
      " - 65s - loss: 0.0982 - categorical_accuracy: 0.9638\n",
      "Epoch 40/200\n",
      " - 65s - loss: 0.0629 - categorical_accuracy: 0.9777\n",
      "Epoch 41/200\n",
      " - 65s - loss: 0.0993 - categorical_accuracy: 0.9628\n",
      "Epoch 42/200\n",
      " - 65s - loss: 0.0855 - categorical_accuracy: 0.9716\n",
      "Epoch 43/200\n",
      " - 66s - loss: 0.0829 - categorical_accuracy: 0.9739\n",
      "Epoch 44/200\n",
      " - 66s - loss: 0.0553 - categorical_accuracy: 0.9833\n",
      "Epoch 45/200\n",
      " - 65s - loss: 0.0686 - categorical_accuracy: 0.9774\n",
      "Epoch 46/200\n",
      " - 65s - loss: 0.0552 - categorical_accuracy: 0.9829\n",
      "Epoch 47/200\n",
      " - 65s - loss: 0.0460 - categorical_accuracy: 0.9860\n",
      "Epoch 48/200\n",
      " - 65s - loss: 0.0549 - categorical_accuracy: 0.9834\n",
      "Epoch 49/200\n",
      " - 65s - loss: 0.0218 - categorical_accuracy: 0.9943\n",
      "Epoch 50/200\n",
      " - 66s - loss: 0.0769 - categorical_accuracy: 0.9780\n",
      "Epoch 51/200\n",
      " - 66s - loss: 0.0225 - categorical_accuracy: 0.9937\n",
      "Epoch 52/200\n",
      " - 65s - loss: 0.0175 - categorical_accuracy: 0.9965\n",
      "Epoch 53/200\n",
      " - 68s - loss: 0.0275 - categorical_accuracy: 0.9907\n",
      "Epoch 54/200\n",
      " - 64s - loss: 0.0677 - categorical_accuracy: 0.9811\n",
      "Epoch 55/200\n",
      " - 64s - loss: 0.0205 - categorical_accuracy: 0.9951\n",
      "Epoch 56/200\n",
      " - 64s - loss: 0.0191 - categorical_accuracy: 0.9941\n",
      "Epoch 57/200\n",
      " - 64s - loss: 0.0349 - categorical_accuracy: 0.9897\n",
      "Epoch 58/200\n",
      " - 64s - loss: 0.0109 - categorical_accuracy: 0.9971\n",
      "Epoch 59/200\n",
      " - 64s - loss: 0.0198 - categorical_accuracy: 0.9932\n",
      "Epoch 60/200\n",
      " - 63s - loss: 0.0980 - categorical_accuracy: 0.9737\n",
      "Epoch 61/200\n",
      " - 64s - loss: 0.0160 - categorical_accuracy: 0.9969\n",
      "Epoch 62/200\n",
      " - 64s - loss: 0.0129 - categorical_accuracy: 0.9962\n",
      "Epoch 63/200\n",
      " - 66s - loss: 0.0107 - categorical_accuracy: 0.9974\n",
      "Epoch 64/200\n",
      " - 66s - loss: 0.0074 - categorical_accuracy: 0.9977\n",
      "Epoch 65/200\n",
      " - 65s - loss: 0.0713 - categorical_accuracy: 0.9845\n",
      "Epoch 66/200\n",
      " - 65s - loss: 0.0085 - categorical_accuracy: 0.9981\n",
      "Epoch 67/200\n",
      " - 65s - loss: 0.0069 - categorical_accuracy: 0.9977\n",
      "Epoch 68/200\n",
      " - 66s - loss: 0.0053 - categorical_accuracy: 0.9988\n",
      "Epoch 69/200\n",
      " - 65s - loss: 0.0061 - categorical_accuracy: 0.9981\n",
      "Epoch 70/200\n",
      " - 65s - loss: 0.1232 - categorical_accuracy: 0.9781\n",
      "Epoch 71/200\n",
      " - 66s - loss: 0.0089 - categorical_accuracy: 0.9978\n",
      "Epoch 72/200\n",
      " - 65s - loss: 0.0082 - categorical_accuracy: 0.9976\n",
      "Epoch 73/200\n",
      " - 67s - loss: 0.0044 - categorical_accuracy: 0.9989\n",
      "Epoch 74/200\n",
      " - 67s - loss: 0.0053 - categorical_accuracy: 0.9992\n",
      "Epoch 75/200\n",
      " - 66s - loss: 0.0133 - categorical_accuracy: 0.9963\n",
      "Epoch 76/200\n",
      " - 67s - loss: 0.0056 - categorical_accuracy: 0.9980\n",
      "Epoch 77/200\n",
      " - 65s - loss: 0.0846 - categorical_accuracy: 0.9762\n",
      "Epoch 78/200\n",
      " - 66s - loss: 0.0051 - categorical_accuracy: 0.9986\n",
      "Epoch 79/200\n",
      " - 65s - loss: 0.0056 - categorical_accuracy: 0.9984\n",
      "Epoch 80/200\n",
      " - 66s - loss: 0.0032 - categorical_accuracy: 0.9989\n",
      "Epoch 81/200\n",
      " - 66s - loss: 0.0054 - categorical_accuracy: 0.9984\n",
      "Epoch 82/200\n",
      " - 65s - loss: 0.0114 - categorical_accuracy: 0.9969\n",
      "Epoch 83/200\n",
      " - 65s - loss: 0.0075 - categorical_accuracy: 0.9978\n",
      "Epoch 84/200\n",
      " - 65s - loss: 0.0052 - categorical_accuracy: 0.9985\n",
      "Epoch 85/200\n",
      " - 65s - loss: 0.0065 - categorical_accuracy: 0.9986\n",
      "Epoch 86/200\n",
      " - 66s - loss: 0.0298 - categorical_accuracy: 0.9928\n",
      "Epoch 87/200\n",
      " - 67s - loss: 0.0051 - categorical_accuracy: 0.9982\n",
      "Epoch 88/200\n",
      " - 67s - loss: 0.0032 - categorical_accuracy: 0.9993\n",
      "Epoch 89/200\n",
      " - 67s - loss: 0.0034 - categorical_accuracy: 0.9992\n",
      "Epoch 90/200\n",
      " - 68s - loss: 0.0074 - categorical_accuracy: 0.9977\n",
      "Epoch 91/200\n",
      " - 69s - loss: 0.0076 - categorical_accuracy: 0.9981\n",
      "Epoch 92/200\n",
      " - 67s - loss: 0.0082 - categorical_accuracy: 0.9986\n",
      "Epoch 93/200\n",
      " - 65s - loss: 0.0036 - categorical_accuracy: 0.9985\n",
      "Epoch 94/200\n",
      " - 66s - loss: 0.0037 - categorical_accuracy: 0.9989\n",
      "Epoch 95/200\n",
      " - 65s - loss: 0.0042 - categorical_accuracy: 0.9988\n",
      "Epoch 96/200\n",
      " - 66s - loss: 0.0031 - categorical_accuracy: 0.9993\n",
      "Epoch 97/200\n",
      " - 67s - loss: 0.0206 - categorical_accuracy: 0.9958\n",
      "Epoch 98/200\n",
      " - 67s - loss: 0.0025 - categorical_accuracy: 0.9995\n",
      "Epoch 99/200\n",
      " - 65s - loss: 0.0037 - categorical_accuracy: 0.9990\n",
      "Epoch 100/200\n",
      " - 66s - loss: 0.0164 - categorical_accuracy: 0.9967\n",
      "Epoch 101/200\n",
      " - 66s - loss: 0.0013 - categorical_accuracy: 0.9999\n",
      "Epoch 102/200\n",
      " - 65s - loss: 0.0014 - categorical_accuracy: 0.9995\n",
      "Epoch 103/200\n",
      " - 65s - loss: 0.0018 - categorical_accuracy: 0.9993\n",
      "Epoch 104/200\n",
      " - 73s - loss: 0.0032 - categorical_accuracy: 0.9989\n",
      "Epoch 105/200\n",
      " - 70s - loss: 0.0027 - categorical_accuracy: 0.9992\n",
      "Epoch 106/200\n",
      " - 66s - loss: 0.0040 - categorical_accuracy: 0.9988\n",
      "Epoch 107/200\n",
      " - 69s - loss: 0.0040 - categorical_accuracy: 0.9984\n",
      "Epoch 108/200\n",
      " - 64s - loss: 9.7789e-04 - categorical_accuracy: 0.9997\n",
      "Epoch 109/200\n",
      " - 64s - loss: 0.0027 - categorical_accuracy: 0.9992\n",
      "Epoch 110/200\n",
      " - 64s - loss: 0.0025 - categorical_accuracy: 0.9989\n",
      "Epoch 111/200\n",
      " - 64s - loss: 6.1748e-04 - categorical_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      " - 64s - loss: 0.0010 - categorical_accuracy: 0.9997\n",
      "Epoch 113/200\n",
      " - 64s - loss: 0.0051 - categorical_accuracy: 0.9995\n",
      "Epoch 114/200\n",
      " - 64s - loss: 0.0048 - categorical_accuracy: 0.9988\n",
      "Epoch 115/200\n",
      " - 64s - loss: 0.0018 - categorical_accuracy: 0.9993\n",
      "Epoch 116/200\n",
      " - 64s - loss: 0.0044 - categorical_accuracy: 0.9992\n",
      "Epoch 117/200\n",
      " - 67s - loss: 0.0014 - categorical_accuracy: 0.9996\n",
      "Epoch 118/200\n",
      " - 66s - loss: 0.0016 - categorical_accuracy: 0.9993\n",
      "Epoch 119/200\n",
      " - 65s - loss: 0.0018 - categorical_accuracy: 0.9996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d3a0ce390>"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(nn_train_deleted, label_total_trans, epochs=200, verbose=2, batch_size = 200,callbacks=[EarlyStopping(monitor='loss', patience=8)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ifweak = np.argmax(nn.predict(x_train_2), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7281816412116401"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balanced_accuracy_score(label_2, y_pred_ifweak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(y_testid.shape[0])\n",
    "#results = np.zeros(y_testid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[test_nrem_idx[0]]=2\n",
    "results[test_weak_idx_original]=1\n",
    "results[test_rem_idx_original]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sum(results == 0) == 0:\n",
    "    print('ok')\n",
    "#    print(balanced_accuracy_score(label_2, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### write to file ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', 'w') as f:\n",
    "    f.write(\"{},{}\\n\".format(\"Id\", \"y\"))\n",
    "    for i in range(len(y_testid)):\n",
    "        f.write(\"{},{}\\n\".format(y_testid[i], results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################  visualization feature  ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_emg = x_train_emg[class1_idx[0][1]]\n",
    "class2_emg = x_train_emg[class2_idx[0][1]]\n",
    "class3_emg = x_train_emg[class3_idx[0][1]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(131)\n",
    "plt.plot(class1_emg)\n",
    "plt.subplot(132)\n",
    "plt.plot(class2_emg)\n",
    "plt.subplot(133)\n",
    "plt.plot(class3_emg)\n",
    "plt.suptitle('emg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class1_eeg1 = x_train_eeg1[class1_idx[0][2],:].reshape((512,1))\n",
    "class1_eeg2 = x_train_eeg2[class1_idx[0][2],:].reshape((512,1))\n",
    "class1_eeg = np.hstack((class1_eeg1, class1_eeg2))\n",
    "class2_eeg1 = x_train_eeg1[class2_idx[0][2],:].reshape((512,1))\n",
    "class2_eeg2 = x_train_eeg2[class2_idx[0][2],:].reshape((512,1))\n",
    "class2_eeg = np.hstack((class2_eeg1, class2_eeg2))\n",
    "class3_eeg1 = x_train_eeg1[class3_idx[0][2],:].reshape((512,1))\n",
    "class3_eeg2 = x_train_eeg2[class3_idx[0][2],:].reshape((512,1))\n",
    "class3_eeg = np.hstack((class3_eeg1, class3_eeg2))\n",
    "\n",
    "def feature_egg(x):\n",
    "    [ts, filtered_sig, features_ts,theta,alpha_low, alpha_high,beta, gamma, plf_pairs, plf]  = eeg.eeg(signal=x, sampling_rate=128.0, show=False)    \n",
    "    return ts, filtered_sig, features_ts,theta,alpha_low, alpha_high,beta, gamma, plf_pairs, plf\n",
    "    \n",
    "def plot_class(x1, x2, x3):\n",
    "    [ts_1, filtered_sig_1, features_ts_1,theta_1,alpha_low_1, alpha_high_1,beta_1, gamma_1, plf_pairs_1, plf_1] = feature_egg(x1)  \n",
    "    [ts_2, filtered_sig_2, features_ts_2,theta_2,alpha_low_2, alpha_high_2,beta_2, gamma_2, plf_pairs_2, plf_2] = feature_egg(x2)  \n",
    "    [ts_3, filtered_sig_3, features_ts_3,theta_3,alpha_low_3, alpha_high_3,beta_3, gamma_3, plf_pairs_3, plf_3] = feature_egg(x3) \n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(features_ts_1,plf_1)\n",
    "    plt.subplot(132)\n",
    "    plt.plot(features_ts_2,plf_2)\n",
    "    plt.subplot(133)\n",
    "    plt.plot(features_ts_3,plf_3)\n",
    "    plt.suptitle('plf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
