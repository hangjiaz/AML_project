{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from biosppy.signals import *\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.models import Model, Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score\n",
    "from sklearn.svm import SVC\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardization(x):\n",
    "    x -= np.mean(x)  \n",
    "    x /= np.std(x)\n",
    "    return x\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_traindata = pd.read_csv(\"train_labels.csv\", header=0)   \n",
    "y_train = y_traindata.iloc[:,1].values\n",
    "\n",
    "testdata = pd.read_csv(\"test_eeg1.csv\", header=0)   \n",
    "y_testid = testdata.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(subject, file):\n",
    "    x_eeg1 = []\n",
    "    with open(\"{}_eeg1.csv\".format(file)) as f:\n",
    "        for line in f.readlines()[21600*(subject-1)+1:21600*subject+1]:\n",
    "            s = list(map(float, line.split(',')[1:]))\n",
    "            x_eeg1.append(s)\n",
    "    x_eeg1= np.array(x_eeg1)\n",
    "\n",
    "    x_eeg2 = []\n",
    "    with open(\"{}_eeg2.csv\".format(file)) as f:\n",
    "        for line in f.readlines()[21600*(subject-1)+1:21600*subject+1]:\n",
    "            s = list(map(float, line.split(',')[1:]))\n",
    "            x_eeg2.append(s)\n",
    "    x_eeg2  = np.array(x_eeg2)\n",
    "\n",
    "    x_emg = []\n",
    "    with open(\"{}_emg.csv\".format(file)) as f:\n",
    "        for line in f.readlines()[21600*(subject-1)+1:21600*subject+1]:\n",
    "            s = list(map(float, line.split(',')[1:]))\n",
    "            x_emg.append(s)\n",
    "    x_emg= np.array(x_emg)\n",
    "    return  x_eeg1,x_eeg2,x_emg \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1_eeg1,  x_train_1_eeg2, x_train_1_emg  = read_data(1,'train')\n",
    "x_train_2_eeg1,  x_train_2_eeg2, x_train_2_emg  = read_data(2,'train')\n",
    "x_train_3_eeg1,  x_train_3_eeg2, x_train_3_emg  = read_data(3, 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1_eeg1,  x_test_1_eeg2, x_test_1_emg  = read_data(1, 'test')\n",
    "x_test_2_eeg1,  x_test_2_eeg2, x_test_2_emg  = read_data(2, 'test')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1 = y_train[0:21600] \n",
    "label_2 = y_train[21600:43200]\n",
    "label_3 = y_train[43200:64800]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def eeg_feature_extraction(x):\n",
    "    X = []\n",
    "    [ts, filtered_sig, features_ts,theta,alpha_low, alpha_high,beta, gamma, plf_pairs, plf]  = eeg.eeg(signal=x, sampling_rate=128.0, show=False)    \n",
    "    X.append(np.mean(theta))\n",
    "    X.append(np.min(theta))\n",
    "    X.append(np.max(theta))\n",
    "    X.append(np.std(theta))\n",
    "    X.append(np.mean(alpha_low))\n",
    "    X.append(np.min(alpha_low))\n",
    "    X.append(np.max(alpha_low))\n",
    "    X.append(np.std(alpha_low))\n",
    "    X.append(np.mean(alpha_high))\n",
    "    X.append(np.min(alpha_high))\n",
    "    X.append(np.max(alpha_high))\n",
    "    X.append(np.std(alpha_high))\n",
    "    X.append(np.mean(beta))\n",
    "    X.append(np.min(beta))\n",
    "    X.append(np.max(beta))\n",
    "    X.append(np.std(beta))\n",
    "    X.append(np.mean(gamma))\n",
    "    X.append(np.min(gamma))\n",
    "    X.append(np.max(gamma))\n",
    "    X.append(np.std(gamma))\n",
    "    X.append(np.mean(plf))\n",
    "    X.append(np.min(plf))\n",
    "    X.append(np.max(plf))\n",
    "    X.append(np.std(plf))\n",
    "    X.append(np.mean(filtered_sig))\n",
    "    X.append(np.std(filtered_sig))\n",
    "    X = np.array(X)\n",
    "        \n",
    "    return X\n",
    "\n",
    "\n",
    "\n",
    "def apply_fun(x):\n",
    "    result = []\n",
    "    for i in range(x.shape[0]):\n",
    "        result.append(eeg_feature_extraction(x[i]))\n",
    "    result = np.array(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1_eeg = np.hstack((x_train_1_eeg1,  x_train_1_eeg2)).reshape((21600,512,2))\n",
    "x_train_1_eeg_extracted = apply_fun(x_train_1_eeg)\n",
    "x_train_2_eeg = np.hstack((x_train_2_eeg1,  x_train_2_eeg2)).reshape((21600,512,2))\n",
    "x_train_2_eeg_extracted = apply_fun(x_train_2_eeg)\n",
    "x_train_3_eeg = np.hstack((x_train_3_eeg1,  x_train_3_eeg2)).reshape((21600,512,2))\n",
    "x_train_3_eeg_extracted = apply_fun(x_train_3_eeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1_eeg = np.hstack((x_test_1_eeg1,  x_test_1_eeg2)).reshape((21600,512,2))\n",
    "x_test_1_eeg_extracted = apply_fun(x_test_1_eeg)\n",
    "x_test_2_eeg = np.hstack((x_test_2_eeg1,  x_test_2_eeg2)).reshape((21600,512,2))\n",
    "x_test_2_eeg_extracted = apply_fun(x_test_2_eeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "x_train_1_eeg_stand= scaler.fit_transform(x_train_1_eeg_extracted)\n",
    "x_train_2_eeg_stand = scaler.fit_transform(x_train_2_eeg_extracted)\n",
    "x_train_3_eeg_stand = scaler.fit_transform(x_train_3_eeg_extracted)\n",
    "x_test_1_eeg_stand= scaler.fit_transform(x_test_1_eeg_extracted)\n",
    "x_test_2_eeg_stand = scaler.fit_transform(x_test_2_eeg_extracted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_eeg = np.concatenate((x_train_1_eeg_stand,x_train_3_eeg_stand),axis = 0)\n",
    "train_eeg = np.concatenate((x_train_1_eeg_stand,x_train_2_eeg_stand,x_train_3_eeg_stand),axis = 0)\n",
    "test_eeg = np.concatenate((x_test_1_eeg_stand,x_test_2_eeg_stand),axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifnrem_1 = (y_train[0:21600] == 2).astype(int)\n",
    "ifnrem_2 = (y_train[21600:43200] == 2).astype(int)\n",
    "ifnrem_3 = (y_train[43200:64800] == 2).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ifnrem_train =  np.concatenate((ifnrem_1,ifnrem_3), axis = 0)\n",
    "ifnrem_train =  np.concatenate((ifnrem_1,ifnrem_2,ifnrem_3), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27133\n",
      "37667\n",
      "(64800, 26)\n"
     ]
    }
   ],
   "source": [
    "print(sum(ifnrem_train == 1))\n",
    "print(sum(ifnrem_train == 0))\n",
    "print(train_eeg.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54266, 26)\n",
      "(54266,)\n"
     ]
    }
   ],
   "source": [
    "print(train_eeg_deleted.shape)\n",
    "print(ifnrem_train_deleted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clf = SVC(C = 3, kernel = 'rbf',decision_function_shape ='ovr', gamma = 'scale')\n",
    "clf.fit(train_eeg, ifnrem_train)\n",
    "y_pred_ifnrem = clf.predict(test_eeg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9531679554099707"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#balanced_accuracy_score(ifnrem_2, y_pred_ifnrem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_nrem_idx = np.where(y_pred_ifnrem == 1)\n",
    "test_other_idx = np.where(y_pred_ifnrem == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1_13_idx = np.where(label_1 != 2 )\n",
    "label_2_13_idx = np.where(label_2 != 2 )\n",
    "label_3_13_idx = np.where(label_3 != 2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1_emg_stand = standardization(x_train_1_emg)\n",
    "x_train_2_emg_stand = standardization(x_train_2_emg)\n",
    "x_train_3_emg_stand = standardization(x_train_3_emg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_1_emg_13 = x_train_1_emg_stand[label_1_13_idx[0]]\n",
    "x_train_2_emg_13 = x_train_2_emg_stand[label_2_13_idx[0]]\n",
    "x_train_3_emg_13 = x_train_3_emg_stand[label_3_13_idx[0]]\n",
    "#x_train_2_emg_13 = x_train_2_emg_stand[test_other_idx[0]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_1_emg_stand = standardization(x_test_1_emg)\n",
    "x_test_2_emg_stand = standardization(x_test_2_emg)\n",
    "x_test_emg_stand = np.concatenate((x_test_1_emg_stand , x_test_2_emg_stand), axis = 0)\n",
    "x_test_emg_13 = x_test_emg_stand[test_other_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_1_13 = label_1[label_1_13_idx[0]]\n",
    "label_2_13 = label_2[label_2_13_idx[0]]\n",
    "label_3_13 = label_3[label_3_13_idx[0]]\n",
    "#label_2_13 = label_2[test_other_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifweak_1_13 = (label_1_13 == 1).astype(int)\n",
    "ifweak_2_13 = (label_2_13 == 1).astype(int)\n",
    "ifweak_3_13 = (label_3_13 == 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nn_train_emg = np.concatenate((x_train_1_emg_13, x_train_3_emg_13),axis = 0)\n",
    "# ifweak_train_13 = np.concatenate((ifweak_1_13,ifweak_3_13),axis = 0)\n",
    "nn_train_emg = np.concatenate((x_train_1_emg_13,x_train_2_emg_13,x_train_3_emg_13),axis = 0)\n",
    "ifweak_train_13 = np.concatenate((ifweak_1_13,ifweak_2_13,ifweak_3_13),axis = 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34114\n",
      "3553\n"
     ]
    }
   ],
   "source": [
    "print(sum(ifweak_train_13 == 1))\n",
    "print(sum(ifweak_train_13 == 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "class1_idx = np.where(ifweak_train_13 == 1)[0]\n",
    "del_class1_idx = np.random.choice(class1_idx, size = len(class1_idx)-sum(ifweak_train_13 == 0), replace=False) \n",
    "nn_train_emg_deleted = np.delete(nn_train_emg, (del_class1_idx), axis = 0) \n",
    "ifweak_train_13_deleted = np.delete(ifweak_train_13, (del_class1_idx), axis = 0) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "ifweak_train_13_trans = keras.utils.to_categorical(ifweak_train_13_deleted, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7106, 2)\n"
     ]
    }
   ],
   "source": [
    "print(ifweak_train_13_trans.shape)\n",
    "#print(x_test_emg_13.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_23 (Reshape)         (None, 512, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_25 (Conv1D)           (None, 500, 1)            14        \n",
      "_________________________________________________________________\n",
      "dropout_69 (Dropout)         (None, 500, 1)            0         \n",
      "_________________________________________________________________\n",
      "max_pooling1d_23 (MaxPooling (None, 250, 1)            0         \n",
      "_________________________________________________________________\n",
      "lstm_23 (LSTM)               (None, 250, 1)            12        \n",
      "_________________________________________________________________\n",
      "dropout_70 (Dropout)         (None, 250, 1)            0         \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 250)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 100)               25100     \n",
      "_________________________________________________________________\n",
      "dropout_71 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "dropout_72 (Dropout)         (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_48 (Dense)             (None, 2)                 102       \n",
      "=================================================================\n",
      "Total params: 30,278\n",
      "Trainable params: 30,278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nn = Sequential()\n",
    "nn.add(InputLayer((512,)))\n",
    "nn.add(Reshape((512,1)))\n",
    "# nn.add(Conv1D(100, 30, strides=1, activation='relu'))\n",
    "# nn.add(Dropout(0.3))\n",
    "nn.add(Conv1D(1, 13, strides=1, activation='relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(MaxPooling1D(2))\n",
    "nn.add(LSTM(1, activation ='relu', return_sequences= True, return_state= False))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Flatten())\n",
    "nn.add(Dense(100,activation = 'relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Dense(50,activation = 'relu'))\n",
    "nn.add(Dropout(0.3))\n",
    "nn.add(Dense(2,activation = 'softmax'))\n",
    "optim = keras.optimizers.Adadelta()\n",
    "nn.compile(optimizer=optim,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['categorical_accuracy'])\n",
    "\n",
    "nn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      " - 24s - loss: 0.3635 - categorical_accuracy: 0.8591\n",
      "Epoch 2/200\n",
      " - 17s - loss: 0.1286 - categorical_accuracy: 0.9659\n",
      "Epoch 3/200\n",
      " - 17s - loss: 0.1161 - categorical_accuracy: 0.9672\n",
      "Epoch 4/200\n",
      " - 16s - loss: 0.1174 - categorical_accuracy: 0.9686\n",
      "Epoch 5/200\n",
      " - 17s - loss: 0.1130 - categorical_accuracy: 0.9692\n",
      "Epoch 6/200\n",
      " - 17s - loss: 0.1114 - categorical_accuracy: 0.9697\n",
      "Epoch 7/200\n",
      " - 17s - loss: 0.1122 - categorical_accuracy: 0.9702\n",
      "Epoch 8/200\n",
      " - 17s - loss: 0.1123 - categorical_accuracy: 0.9688\n",
      "Epoch 9/200\n",
      " - 16s - loss: 0.1090 - categorical_accuracy: 0.9700\n",
      "Epoch 10/200\n",
      " - 16s - loss: 0.1103 - categorical_accuracy: 0.9689\n",
      "Epoch 11/200\n",
      " - 17s - loss: 0.1109 - categorical_accuracy: 0.9692\n",
      "Epoch 12/200\n",
      " - 17s - loss: 0.1089 - categorical_accuracy: 0.9702\n",
      "Epoch 13/200\n",
      " - 16s - loss: 0.1110 - categorical_accuracy: 0.9690\n",
      "Epoch 14/200\n",
      " - 16s - loss: 0.1097 - categorical_accuracy: 0.9692\n",
      "Epoch 15/200\n",
      " - 17s - loss: 0.1105 - categorical_accuracy: 0.9690\n",
      "Epoch 16/200\n",
      " - 17s - loss: 0.1080 - categorical_accuracy: 0.9702\n",
      "Epoch 17/200\n",
      " - 16s - loss: 0.1085 - categorical_accuracy: 0.9702\n",
      "Epoch 18/200\n",
      " - 16s - loss: 0.1091 - categorical_accuracy: 0.9692\n",
      "Epoch 19/200\n",
      " - 17s - loss: 0.1084 - categorical_accuracy: 0.9695\n",
      "Epoch 20/200\n",
      " - 16s - loss: 0.1072 - categorical_accuracy: 0.9703\n",
      "Epoch 21/200\n",
      " - 16s - loss: 0.1092 - categorical_accuracy: 0.9697\n",
      "Epoch 22/200\n",
      " - 17s - loss: 0.1071 - categorical_accuracy: 0.9689\n",
      "Epoch 23/200\n",
      " - 17s - loss: 0.1081 - categorical_accuracy: 0.9686\n",
      "Epoch 24/200\n",
      " - 16s - loss: 0.1053 - categorical_accuracy: 0.9710\n",
      "Epoch 25/200\n",
      " - 16s - loss: 0.1057 - categorical_accuracy: 0.9704\n",
      "Epoch 26/200\n",
      " - 17s - loss: 0.1058 - categorical_accuracy: 0.9706\n",
      "Epoch 27/200\n",
      " - 17s - loss: 0.1056 - categorical_accuracy: 0.9702\n",
      "Epoch 28/200\n",
      " - 17s - loss: 0.1072 - categorical_accuracy: 0.9700\n",
      "Epoch 29/200\n",
      " - 16s - loss: 0.1072 - categorical_accuracy: 0.9693\n",
      "Epoch 30/200\n",
      " - 17s - loss: 0.1060 - categorical_accuracy: 0.9688\n",
      "Epoch 31/200\n",
      " - 17s - loss: 0.1054 - categorical_accuracy: 0.9704\n",
      "Epoch 32/200\n",
      " - 16s - loss: 0.1030 - categorical_accuracy: 0.9714\n",
      "Epoch 33/200\n",
      " - 16s - loss: 0.1073 - categorical_accuracy: 0.9696\n",
      "Epoch 34/200\n",
      " - 16s - loss: 0.1055 - categorical_accuracy: 0.9714\n",
      "Epoch 35/200\n",
      " - 17s - loss: 0.1053 - categorical_accuracy: 0.9703\n",
      "Epoch 36/200\n",
      " - 17s - loss: 0.1066 - categorical_accuracy: 0.9696\n",
      "Epoch 37/200\n",
      " - 17s - loss: 0.1054 - categorical_accuracy: 0.9703\n",
      "Epoch 38/200\n",
      " - 16s - loss: 0.1065 - categorical_accuracy: 0.9696\n",
      "Epoch 39/200\n",
      " - 17s - loss: 0.1054 - categorical_accuracy: 0.9709\n",
      "Epoch 40/200\n",
      " - 17s - loss: 0.1042 - categorical_accuracy: 0.9710\n",
      "Epoch 41/200\n",
      " - 16s - loss: 0.1053 - categorical_accuracy: 0.9707\n",
      "Epoch 42/200\n",
      " - 17s - loss: 0.1057 - categorical_accuracy: 0.9697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1d8cb34160>"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.fit(nn_train_emg_deleted, ifweak_train_13_trans, epochs=200, verbose=2, batch_size = 200,callbacks=[EarlyStopping(monitor='loss', patience=10)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_ifweak = np.argmax(nn.predict(x_test_emg_13), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9733005596138045"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#balanced_accuracy_score(ifweak_2_13, y_pred_ifweak)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_weak_idx = np.where(y_pred_ifweak == 1)\n",
    "test_rem_idx = np.where(y_pred_ifweak == 0)\n",
    "test_weak_idx_original = test_other_idx[0][test_weak_idx[0]]\n",
    "test_rem_idx_original = test_other_idx[0][test_rem_idx[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = np.zeros(y_testid.shape[0])\n",
    "#results = np.zeros(y_testid.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "results[test_nrem_idx[0]]=2\n",
    "results[test_weak_idx_original]=1\n",
    "results[test_rem_idx_original]=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "if sum(results == 0) == 0:\n",
    "    print('ok')\n",
    "#    print(balanced_accuracy_score(label_2, results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################### write to file ######################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('output.csv', 'w') as f:\n",
    "    f.write(\"{},{}\\n\".format(\"Id\", \"y\"))\n",
    "    for i in range(len(y_testid)):\n",
    "        f.write(\"{},{}\\n\".format(y_testid[i], results[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#######################  visualization feature  ######################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class1_emg = x_train_emg[class1_idx[0][1]]\n",
    "class2_emg = x_train_emg[class2_idx[0][1]]\n",
    "class3_emg = x_train_emg[class3_idx[0][1]]\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(131)\n",
    "plt.plot(class1_emg)\n",
    "plt.subplot(132)\n",
    "plt.plot(class2_emg)\n",
    "plt.subplot(133)\n",
    "plt.plot(class3_emg)\n",
    "plt.suptitle('emg')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "class1_eeg1 = x_train_eeg1[class1_idx[0][2],:].reshape((512,1))\n",
    "class1_eeg2 = x_train_eeg2[class1_idx[0][2],:].reshape((512,1))\n",
    "class1_eeg = np.hstack((class1_eeg1, class1_eeg2))\n",
    "class2_eeg1 = x_train_eeg1[class2_idx[0][2],:].reshape((512,1))\n",
    "class2_eeg2 = x_train_eeg2[class2_idx[0][2],:].reshape((512,1))\n",
    "class2_eeg = np.hstack((class2_eeg1, class2_eeg2))\n",
    "class3_eeg1 = x_train_eeg1[class3_idx[0][2],:].reshape((512,1))\n",
    "class3_eeg2 = x_train_eeg2[class3_idx[0][2],:].reshape((512,1))\n",
    "class3_eeg = np.hstack((class3_eeg1, class3_eeg2))\n",
    "\n",
    "def feature_egg(x):\n",
    "    [ts, filtered_sig, features_ts,theta,alpha_low, alpha_high,beta, gamma, plf_pairs, plf]  = eeg.eeg(signal=x, sampling_rate=128.0, show=False)    \n",
    "    return ts, filtered_sig, features_ts,theta,alpha_low, alpha_high,beta, gamma, plf_pairs, plf\n",
    "    \n",
    "def plot_class(x1, x2, x3):\n",
    "    [ts_1, filtered_sig_1, features_ts_1,theta_1,alpha_low_1, alpha_high_1,beta_1, gamma_1, plf_pairs_1, plf_1] = feature_egg(x1)  \n",
    "    [ts_2, filtered_sig_2, features_ts_2,theta_2,alpha_low_2, alpha_high_2,beta_2, gamma_2, plf_pairs_2, plf_2] = feature_egg(x2)  \n",
    "    [ts_3, filtered_sig_3, features_ts_3,theta_3,alpha_low_3, alpha_high_3,beta_3, gamma_3, plf_pairs_3, plf_3] = feature_egg(x3) \n",
    "    \n",
    "   \n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.subplot(131)\n",
    "    plt.plot(features_ts_1,plf_1)\n",
    "    plt.subplot(132)\n",
    "    plt.plot(features_ts_2,plf_2)\n",
    "    plt.subplot(133)\n",
    "    plt.plot(features_ts_3,plf_3)\n",
    "    plt.suptitle('plf')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
