{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from biosppy.signals import ecg \n",
    "import math\n",
    "import keras\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "################ read data\n",
    "y_traindata = pd.read_csv(\"y_train.csv\", header=0)   \n",
    "y_train = y_traindata.iloc[:,1].values\n",
    "\n",
    "\n",
    "x_train = []\n",
    "with open(\"X_train.csv\") as f_train:\n",
    "    for line in f_train.readlines()[1:]:\n",
    "        s = list(map(int, line.split(',')[1:]))\n",
    "        if len(s) < 17813:\n",
    "            s.extend([0 for x in range(len(s), 17813)])\n",
    "        x_train.append(s)\n",
    "x_train = np.array(x_train)\n",
    "\n",
    "\n",
    "################# split data\n",
    "x_ktrain, x_ktest, y_ktrain, y_ktest = train_test_split(x_train, y_train, test_size=0.4, random_state=0)\n",
    "\n",
    "\n",
    "################## downsampling\n",
    "\n",
    "class0_idx = np.where(y_ktrain == 0)[0]\n",
    "\n",
    "#for i range(k):\n",
    "    \n",
    "np.random.seed(0)\n",
    "del_class0_idx = np.random.choice(class0_idx, size = len(class0_idx)-sum(y_ktrain == 2), replace=False) \n",
    "print('del_class0_idx:', del_class0_idx[:5])\n",
    "x_ktrain = np.delete(x_ktrain, (del_class0_idx), axis = 0) \n",
    "y_ktrain = np.delete(y_ktrain, (del_class0_idx), axis = 0) \n",
    "print('downsampling shape:', sum(y_ktrain == 0), sum(y_ktrain == 1), sum(y_ktrain == 2), sum(y_ktrain == 3))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ts (array) – Signal time axis reference (seconds).\n",
    "# filtered (array) – Filtered ECG signal.\n",
    "# rpeaks (array) – R-peak location indices.\n",
    "# templates_ts (array) – Templates time axis reference (seconds).\n",
    "# templates (array) – Extracted heartbeat templates.\n",
    "# heart_rate_ts (array) – Heart rate time axis reference (seconds).\n",
    "# heart_rate (array) – Instantaneous heart rate (bpm).\n",
    "def feature_extraction(x):\n",
    "    [ts, filtered_sig, rpeaks, temp_ts, temp, hr_ts, heart_rate]  = ecg.ecg(signal = x, sampling_rate=300.0, show=False)\n",
    "    rpeaks = ecg.correct_rpeaks(signal=x, rpeaks=rpeaks, sampling_rate=300, tol=0.1)[0]\n",
    "    extracted = np.zeros((temp.shape[0],(temp.shape[1]+4)))\n",
    "    extracted[:,:temp.shape[1]] = temp\n",
    "    rr_interval = np.diff(rpeaks)/300\n",
    "    for i in range(1,len(rpeaks)-1):\n",
    "        RR_curr =  rr_interval[i-1]\n",
    "        RR_next = rr_interval[i]\n",
    "        extracted[i,-4]=math.log(RR_curr)\n",
    "        extracted[i,-3]=math.log(RR_next)        \n",
    "    extracted[0,-3] =  math.log(rr_interval[0])\n",
    "    extracted[-1,-4] = math.log(rr_interval[-1])  \n",
    "    extracted[:,-2] =  np.mean(rr_interval)\n",
    "    extracted[:,-1] = np.var(1/rr_interval)      \n",
    "    return extracted, len(rpeaks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "[ts, filtered_sig, rpeaks, temp_ts, temp, hr_ts, heart_rate]  = ecg.ecg(signal = x_ktrain[0], sampling_rate=300.0, show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(np.mean(temp, axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17813,)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_sig.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.apply_along_axis(feature_extraction, 1, x_ktrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = np.apply_along_axis(feature_extraction, 1, x_ktest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_input = []\n",
    "nn_test = []\n",
    "min_num = np.min((np.min(train_data[:,1]), np.min(test_data[:,1])))\n",
    "for i in range(train_data[:,0].shape[0]):   \n",
    "    nn_input.append(train_data[i,0][:min_num])\n",
    "nn_input = np.array(nn_input)\n",
    "\n",
    "for j in range(test_data[:,0].shape[0]):    \n",
    "    nn_test.append(test_data[j,0][:min_num])\n",
    "nn_test = np.array(nn_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (2157, 7, 184)\n",
      "test: (2047, 7, 184)\n",
      "stand_train: (2157, 7, 184)\n",
      "stand_test: (2047, 7, 184)\n"
     ]
    }
   ],
   "source": [
    "print('train:', nn_input.shape)\n",
    "print('test:', nn_test.shape)\n",
    "nn_stand_input = []\n",
    "nn_stand_test = []\n",
    "scaler = StandardScaler()\n",
    "\n",
    "stand_input = np.reshape(nn_input,(nn_input.shape[0]*min_num,nn_input.shape[2] ) )\n",
    "stand_input = scaler.fit_transform(stand_input)\n",
    "stand_input = stand_input.reshape((nn_input.shape[0],min_num, nn_input.shape[2] ))\n",
    "print('stand_train:', stand_input.shape)\n",
    "\n",
    "stand_test = np.reshape(nn_test,(nn_test.shape[0]*min_num,nn_test.shape[2] ) )\n",
    "stand_test = scaler.transform(stand_test)\n",
    "stand_test = stand_test.reshape((nn_test.shape[0],min_num, nn_test.shape[2] ))\n",
    "print('stand_test:', stand_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_14 (LSTM)               (None, 500)               1370000   \n",
      "_________________________________________________________________\n",
      "dense_39 (Dense)             (None, 150)               75150     \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 50)                7550      \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 4)                 204       \n",
      "=================================================================\n",
      "Total params: 1,452,904\n",
      "Trainable params: 1,452,904\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "############# model construction\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7,184,)))\n",
    "model.add(LSTM(500, activation = None, return_sequences= False, return_state= False))\n",
    "model.add(Dense(150, activation=None, kernel_initializer='random_uniform'))\n",
    "model.add(Dense(50, activation=None, kernel_initializer='random_uniform'))\n",
    "model.add(Dense(4, activation='softmax'))\n",
    "optim = keras.optimizers.Adadelta()\n",
    "model.compile(optimizer=optim,\n",
    "          loss='categorical_crossentropy',\n",
    "          metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_ktrain_encodeing = keras.utils.to_categorical(y_ktrain, 4)\n",
    "print(y_ktrain[0])\n",
    "model.fit(stand_input, y_ktrain_encodeing, epochs=100, verbose=1, batch_size=40, callbacks=[EarlyStopping(monitor='loss', patience=6)])\n",
    "\n",
    "y_kpred = np.argmax(model.predict(stand_test), axis=1)\n",
    "\n",
    "score = f1_score(y_ktest, y_kpred, average='micro')\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_extraction(x):\n",
    "    X = []\n",
    "\n",
    "    [ts, filtered_sig, rpeaks, temp_ts, temp, hr_ts, heart_rate]  = ecg.ecg(signal = x, sampling_rate=300, show=False)\n",
    "    rpeaks = ecg.correct_rpeaks(signal=x, rpeaks=rpeaks, sampling_rate=300, tol=0.1)\n",
    "    \n",
    "    peaks = x[rpeaks]\n",
    "    if len(heart_rate) < 2:\n",
    "        heart_rate = [0, 1]\n",
    "    if len(hr_ts) < 2:\n",
    "        hr_ts = [0, 1]\n",
    "    \n",
    "    X.append(np.mean(peaks))\n",
    "    X.append(np.min(peaks))\n",
    "    X.append(np.max(peaks))\n",
    "    X.append(np.mean(np.diff(rpeaks)))\n",
    "    X.append(np.min(np.diff(rpeaks)))\n",
    "    X.append(np.max(np.diff(rpeaks)))\n",
    "    X.append(np.mean(heart_rate))\n",
    "    X.append(np.min(heart_rate))\n",
    "    X.append(np.max(heart_rate))\n",
    "    X.append(np.mean(np.diff(heart_rate)))\n",
    "    X.append(np.min(np.diff(heart_rate)))\n",
    "    X.append(np.max(np.diff(heart_rate)))\n",
    "    X.append(np.mean(np.diff(hr_ts)))\n",
    "    X.append(np.min(np.diff(hr_ts)))\n",
    "    X.append(np.max(np.diff(hr_ts)))\n",
    "    X.append(np.var(np.diff(hr_ts)))\n",
    "    X.append(np.sum(filtered_sig))\n",
    "    \n",
    "    X += list(np.mean(temp, axis=0))\n",
    "    X += list(np.min(temp, axis=0))\n",
    "    X += list(np.max(temp, axis=0))\n",
    "    X = np.array(X)\n",
    "    \n",
    "\n",
    "    return X\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.apply_along_axis(feature_extraction, 1, x_ktrain)\n",
    "test_data = np.apply_along_axis(feature_extraction, 1, x_ktest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2157, 17813)\n",
      "(2047, 17813)\n"
     ]
    }
   ],
   "source": [
    "print(x_ktrain.shape)\n",
    "print(x_ktest.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
